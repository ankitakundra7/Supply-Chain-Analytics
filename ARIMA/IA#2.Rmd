---
title : "" 
output: html_notebook
---
***
<center>
## Individual Assignment #2: ARIMA Lab.
#### Due: Nov. 23 before class time
#### (40 points)
#### Ankita Kundra (ak44675)
</center>
***

The file titled **US Electricity.csv** includes a time series index compiled by the US Federal Reserve representing total fossil-fuel US electricity generation by all utilities from January 1939 through October 2021.

In the following code box we read the CSV file and set up the data as a *tsibble* and then we plot it and subset it to examine it.

```{r}
library(fpp3)

D <- read.csv("US Electricity.csv") %>% 
  mutate(DATE = yearmonth(DATE)) %>%
  as_tsibble(index = DATE)
  
D %>% autoplot(ELEC)

DR <- D %>% filter(DATE >= yearmonth("2010 Jan"))

DR %>% autoplot(ELEC)
```

We are interested in developing a two-year long monthly forecast (24 months) for the national electricity production requirements. 


1. Examine the stationarity of the **ELEC** time series in the reduced **DR** data, examine also the corresponding ACF and PACF diagrams and propose three plausible ARIMA models to fit the data.


The first step in fitting an ARIMA model to model a time-series is to determine if the time series is stationary and if it is not, determine how many differences is neccessary to make it stationary.

```{r}


DR %>% 
  mutate(diff.E = difference(ELEC),
         diff2.E = difference(diff.E)) -> DE

```


```{r, warning = FALSE}

# Examine Stationarity Visually

DE %>% gg_tsdisplay(ELEC, plot_type = "partial")  
DE %>% gg_tsdisplay(diff.E, plot_type = "partial")
DE %>% gg_tsdisplay(diff2.E, plot_type = "partial")

```
From the visual examination of the plots it is apparent that the *ELEC* time-series is not stationary, but the first and second difference may be.

Next we examine ADF and the unit roots test results on these three time series.

The Null Hypothesis of the KPSS root test is that data is stationary, hence we need to obtain a large value of p so we CANNOT reject the Null Hypothesis

On the other hand the Null Hypothesis of the ADF test is that the data is NOT stationary, hence we need to obtain a small p-value to reject the Null Hypotehsis.


```{r}

# Unit Root Test
DE %>% features(ELEC, unitroot_kpss)
DE %>% features(diff.E, unitroot_kpss)
DE %>% features(diff2.E, unitroot_kpss)

DE %>% features(ELEC, unitroot_ndiffs)

# ADF Test
DE$ELEC%>% adf.test()

DE$diff.E %>%
  na.omit() %>%
  adf.test()

DE$diff2.E %>%
  na.omit() %>%
  adf.test()

```

According to the KPSS test we need to difference *ELEC* twice before fitting the model. On the other hand the ADF test indicates that we may be able to fit a model to the date differencing it once or twice.

Based on ACF and PACF plots, following 3 models are recommended:

1. '[3,0,0][1,1,0] m=12'
2. '[2,0,0][1,1,0] m=12'
3. '[1,0,0][1,1,0] m=12'

There is yearly seasonality in the data, and 3 strong PACF terms. Seasonally differencing once with m=12 should be a good model for this data.


2. Using **fable** fit the following five models to the **DR** data: (i)-(iii) the three models you propose in (1), (iv) the automatically selected model by the ARIMA() functionn, and (v) the automatically selected model by the ETS() function.  Report the name/order of each model and the corresponding AICc and BIC.

```{r}
m <- DE %>% model(m1 = ARIMA(ELEC ~ pdq(3,0,0) + PDQ(1,1,0)),
                 m2 = ARIMA(ELEC ~ pdq(2,0,0) + PDQ(1,1,0)),
                 m3 = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(1,1,0)),
                 m4 = ARIMA(ELEC),
                 m5 = ETS(ELEC))
                 
m %>% glance() %>%
  select(.model, AICc, BIC)
```

Here, 
m1 is ARIMA model '[3,0,0][1,1,0] m=12'
m2 is ARIMA model '[2,0,0][1,1,0] m=12'
m3 is ARIMA model  '[1,0,0][1,1,0] m=12'
m4 is ARIMA auto
m5 is ETS


3. Examine the residuals of all the models using the Ljung-Box test and the **gg_tsresiduals()** function. Is there a validity problem with any of the models?


```{r}
m %>% augment() %>%
  features(.resid, ljung_box, lag = 10)


m %>% select(m1) %>% gg_tsresiduals()
m %>% select(m2) %>% gg_tsresiduals()
m %>% select(m3) %>% gg_tsresiduals()
m %>% select(m4) %>% gg_tsresiduals()
m %>% select(m5) %>% gg_tsresiduals()
```


The analysis above implies that we cannot reject the residual independence hypothesis for ARIMA the models. The high p values of the ARIMA models indicate that the residuals are uncorrelated. 


4. For the set of five models selected (automatically and/or manually)  examine the in-sample accuracy metrics.  Based on a holistic analysis of the information criteria select the best two ARIMA models and the ETS model. Report the model name/order and their parameter values.


```{r}
m %>% glance() %>%
  select(.model, AICc, BIC)
```

Here, 
m1 is ARIMA model '[3,0,0][1,1,0] m=12'
m2 is ARIMA model '[2,0,0][1,1,0] m=12'
m3 is ARIMA model  '[1,0,0][1,1,0] m=12'
m4 is ARIMA auto
m5 is ETS

```{r}
m %>% select(m1) %>% report()
m %>% select(m2) %>% report()
m %>% select(m3) %>% report()
m %>% select(m4) %>% report()
m %>% select(m5) %>% report()
```

On the basis of the AICc values of the 5 models, we can conclude that the ARIMA auto model ([1,0,0][2,1,0]m=12) performs the best overall followed by the 2 manual ARIMA models - [1,0,0][1,1,0]m=12 and [2,0,0][1,1,0]m=12

For 5:
For model cross-validation purposes stretch the DR data as follows:

```{r, warning=FALSE}
D.CV <- DR %>%
  filter(DATE >= yearmonth("2010 Jan")) %>%
  stretch_tsibble(.init = 36, .step = 1)
```


5. Fit cross-validation models for each of the time sub-series in the stretched data for each of the four model types selected in (4). In the case(s) where the models were automatically selected, do NOT run the automatic selection under cross validation, instead enter manually the model order/type when you call the ARIMA()/ETS() function. 

```{r, warning=FALSE}
mC <- D.CV %>% 
  model(arima200110 = ARIMA(ELEC ~ pdq(2,0,0) + PDQ(1,1,0)),
    arima100110 = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(1,1,0)),
    arima_100210= ARIMA(ELEC ~ pdq(1,0,0)+ PDQ(2,1,0)),
    ETS_auto = ETS(ELEC ~ error("M") + trend(N) + season("A")))

mC
```

6. Prepare a 24-month ahead forecast foe each of the models fitted in (5) and prepare a plot of MAPE vs months-ahead.  Based on the dynamic behavior of cross-validation MAPE discuss which model(s) should be kept/discarded.


```{r}

mC %>% 
  forecast(h = 24) %>%
  group_by(.id, .model) %>%
  mutate(h = row_number()) %>%
  ungroup() -> fCV
```
  
  
```{r, warning=FALSE}

fCV %>%
  accuracy(DR, by = c("h", ".model")) %>%
  ggplot(aes(x = h, y = MAPE, color = .model)) +
  geom_line()

```



From the cross validation metrics it seems that the ETS model does not perform as expected and should be discarded.

7. Examine the cross-validation residuals of the models you selected in (6), and based on their correlation (model vs. model) discuss if it is advisable to prepare an ensemble forecast averaging the forecasts of two or more models.

The RMSE plots for the models are as follows :

```{r}
fCV %>%
  accuracy(DR, by = c("h", ".model")) %>%
  ggplot(aes(x = h, y = RMSE, color = .model)) +
  geom_line()

```

It is observed that the ETS model does not perform as expected and hence we would not prefer to keep it in the ensemble model. Of the others, the Arima Auto [1,0,0][2,1,0]m=12 model has lower RMSE (in ranges of 4) compared to the other 2 models - ARIMA [2,0,0][1,1,0]m=12 and ARIMA [1,0,0][1,1,0]m=12 (above 5). 
We can explore ensemble model if the errors of these models offset each other as a combination.



8. The index is very useful for energy planning purpose as most of the variability and seasonality is produced by combined cycle natural gas plants and single cycle peaker plants that also run on natural gas (i.e., nuclear and coal generation is fixed and relatively constant).  For this purpose it is of interest to know what is the production index level that will not be seperated with a probability (service-level) of 95%. For the best model in (6) plot the 24-month ahead forecast and plot the forecast and the corresponding confidence interval to help you address the service level question. Report numerically the month-by-month the index forecasts that meet the desired 95% service level.


Taking the parameters of the Arima Auto Model as the best model :- 

```{r, message=FALSE}
m_best <- DR%>%model(arima_best = ARIMA(ELEC ~ pdq(1,0,0) + PDQ(2,1,0)))
frcast_24 <- m_best%>%forecast(h=24)
frcast_24%>%autoplot()+geom_line(data = DE, mapping = aes(y = ELEC), col = "grey")
```

For the 95% desired level :-
```{r, warning =FALSE}
frcast_24%>%autoplot()
```

```{r}
frcast_24 %>%  hilo(level =c(95)) %>%
  unpack_hilo("95%") %>%
  select(ELEC,"95%_lower", "95%_upper")
```






